{
  "Llama-3.1-8B": [
    {
      "duration": 4.076426029205322,
      "total_output_tokens": 12478,
      "responses": 32,
      "gpu_avg_power": 440.58326153846156,
      "cpu_avg_power": 0.0,
      "dram_avg_power": 0.0,
      "total_avg_power": 0,
      "gpu_energy": 1796.0050753675607,
      "cpu_energy": 0.0,
      "dram_energy": 0.0,
      "total_energy": 1796.0050753675607,
      "energy_per_token": 0.14393372939313678,
      "gpu_energy_per_second": 440.58326153846156,
      "cpu_energy_per_second": 0.0,
      "dram_energy_per_second": 0.0,
      "total_energy_per_second": 0.0,
      "gpu_energy_per_token": 0.14393372939313678,
      "cpu_energy_per_token": 0.0,
      "dram_energy_per_token": 0.0,
      "total_energy_per_token": 0.0,
      "gpu_energy_per_response": 112.25031721047255,
      "cpu_energy_per_response": 0.0,
      "dram_energy_per_response": 0.0,
      "total_energy_per_response": 0.0,
      "gpu0_power_watts": 255.4508153846154,
      "gpu1_power_watts": 60.63243076923079,
      "gpu2_power_watts": 63.330353846153876,
      "gpu3_power_watts": 61.169661538461554,
      "psys_power_watts": 0.0,
      "package-1_power_watts": 0.0,
      "package-1-dram_power_watts": 0.0,
      "package-0_power_watts": 0.0,
      "package-0-dram_power_watts": 0.0,
      "dram_domains": [
        "package-1-dram",
        "package-0-dram"
      ],
      "cpu_domain_power": {
        "psys": 0.0,
        "package-1": 0.0,
        "package-1-dram": 0.0,
        "package-0": 0.0,
        "package-0-dram": 0.0
      },
      "gpu_memory_after_load_mb": 87172.56,
      "gpu_memory_total_mb": 95830.0,
      "model": "Llama-3.1-8B",
      "batch_size": 256,
      "engine": "vllm",
      "gpu_energy_per_second_formatted": "440.58J/s",
      "cpu_energy_per_second_formatted": "0.00J/s",
      "dram_energy_per_second_formatted": "0.00J/s",
      "total_energy_per_second_formatted": "0.00J/s",
      "gpu_energy_per_token_mj": 143.9337293931368,
      "cpu_energy_per_token_mj": 0.0,
      "dram_energy_per_token_mj": 0.0,
      "total_energy_per_token_mj": 0.0,
      "gpu_power_formatted": "440.58W",
      "cpu_power_formatted": "0.00W",
      "dram_power_formatted": "0.00W",
      "total_power_formatted": "0.00W",
      "gpu_energy_formatted": "1796.01J",
      "cpu_energy_formatted": "0.00J",
      "dram_energy_formatted": "0.00J",
      "total_energy_formatted": "1796.01J",
      "gpu_energy_per_response_formatted": "112.250J/response",
      "cpu_energy_per_response_formatted": "0.000J/response",
      "dram_energy_per_response_formatted": "0.000J/response",
      "total_energy_per_response_formatted": "0.000J/response",
      "formatted_output": "\nPower and Energy Metrics:\n==================================================\n\nBasic Information:\n  Runtime: 4.08s\n  Generated tokens: 12478\n  Number of responses: 32\n\nAverage Power:\n  GPU Power: 440.58W\n  CPU Power: 0.00W\n  DRAM Power: 0.00W\n  Total Power: 0.00W\n\nTotal Energy Consumption:\n  GPU Energy: 1796.01J\n  CPU Energy: 0.00J\n  DRAM Energy: 0.00J\n  Total Energy: 1796.01J\n\nEnergy per Second:\n  GPU Energy/s: 440.58J/s\n  CPU Energy/s: 0.00J/s\n  DRAM Energy/s: 0.00J/s\n  Total Energy/s: 0.00J/s\n\nEnergy per Token:\n  GPU Energy/token: 143.934mJ/token\n  CPU Energy/token: 0.000mJ/token\n  DRAM Energy/token: 0.000mJ/token\n  Total Energy/token: 0.000mJ/token\n\nEnergy per Response:\n  GPU Energy/response: 112.250J/response\n  CPU Energy/response: 0.000J/response\n  DRAM Energy/response: 0.000J/response\n  Total Energy/response: 0.000J/response\n=================================================="
    }
  ]
}