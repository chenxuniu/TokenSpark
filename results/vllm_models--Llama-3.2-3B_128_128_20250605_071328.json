{
  "Llama-3.2-3B": [
    {
      "duration": 1.8243136405944824,
      "total_output_tokens": 22342,
      "responses": 256,
      "gpu_avg_power": 354.5678541666667,
      "cpu_avg_power": 0.0,
      "dram_avg_power": 0.0,
      "total_avg_power": 0,
      "gpu_energy": 646.8429728725652,
      "cpu_energy": 0.0,
      "dram_energy": 0.0,
      "total_energy": 646.8429728725652,
      "energy_per_token": 0.02895188312919905,
      "gpu_energy_per_second": 354.5678541666666,
      "cpu_energy_per_second": 0.0,
      "dram_energy_per_second": 0.0,
      "total_energy_per_second": 0.0,
      "gpu_energy_per_token": 0.02895188312919905,
      "cpu_energy_per_token": 0.0,
      "dram_energy_per_token": 0.0,
      "total_energy_per_token": 0.0,
      "gpu_energy_per_response": 58.80390662477865,
      "cpu_energy_per_response": 0.0,
      "dram_energy_per_response": 0.0,
      "total_energy_per_response": 0.0,
      "gpu0_power_watts": 168.26427083333337,
      "gpu1_power_watts": 63.7279375,
      "gpu2_power_watts": 62.15291666666666,
      "gpu3_power_watts": 60.42272916666667,
      "psys_power_watts": 0.0,
      "package-1_power_watts": 0.0,
      "package-1-dram_power_watts": 0.0,
      "package-0_power_watts": 0.0,
      "package-0-dram_power_watts": 0.0,
      "dram_domains": [
        "package-1-dram",
        "package-0-dram"
      ],
      "cpu_domain_power": {
        "psys": 0.0,
        "package-1": 0.0,
        "package-1-dram": 0.0,
        "package-0": 0.0,
        "package-0-dram": 0.0
      },
      "gpu_memory_after_load_mb": 87006.56,
      "gpu_memory_total_mb": 95830.0,
      "model": "Llama-3.2-3B",
      "batch_size": 128,
      "engine": "vllm",
      "gpu_energy_per_second_formatted": "354.57J/s",
      "cpu_energy_per_second_formatted": "0.00J/s",
      "dram_energy_per_second_formatted": "0.00J/s",
      "total_energy_per_second_formatted": "0.00J/s",
      "gpu_energy_per_token_mj": 28.95188312919905,
      "cpu_energy_per_token_mj": 0.0,
      "dram_energy_per_token_mj": 0.0,
      "total_energy_per_token_mj": 0.0,
      "gpu_power_formatted": "354.57W",
      "cpu_power_formatted": "0.00W",
      "dram_power_formatted": "0.00W",
      "total_power_formatted": "0.00W",
      "gpu_energy_formatted": "646.84J",
      "cpu_energy_formatted": "0.00J",
      "dram_energy_formatted": "0.00J",
      "total_energy_formatted": "646.84J",
      "gpu_energy_per_response_formatted": "58.804J/response",
      "cpu_energy_per_response_formatted": "0.000J/response",
      "dram_energy_per_response_formatted": "0.000J/response",
      "total_energy_per_response_formatted": "0.000J/response",
      "formatted_output": "\nPower and Energy Metrics:\n==================================================\n\nBasic Information:\n  Runtime: 1.82s\n  Generated tokens: 22342\n  Number of responses: 256\n\nAverage Power:\n  GPU Power: 354.57W\n  CPU Power: 0.00W\n  DRAM Power: 0.00W\n  Total Power: 0.00W\n\nTotal Energy Consumption:\n  GPU Energy: 646.84J\n  CPU Energy: 0.00J\n  DRAM Energy: 0.00J\n  Total Energy: 646.84J\n\nEnergy per Second:\n  GPU Energy/s: 354.57J/s\n  CPU Energy/s: 0.00J/s\n  DRAM Energy/s: 0.00J/s\n  Total Energy/s: 0.00J/s\n\nEnergy per Token:\n  GPU Energy/token: 28.952mJ/token\n  CPU Energy/token: 0.000mJ/token\n  DRAM Energy/token: 0.000mJ/token\n  Total Energy/token: 0.000mJ/token\n\nEnergy per Response:\n  GPU Energy/response: 58.804J/response\n  CPU Energy/response: 0.000J/response\n  DRAM Energy/response: 0.000J/response\n  Total Energy/response: 0.000J/response\n=================================================="
    }
  ]
}