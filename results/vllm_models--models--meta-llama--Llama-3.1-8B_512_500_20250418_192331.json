{
  "models--meta-llama--Llama-3.1-8B": [
    {
      "duration": 969.0938668251038,
      "total_output_tokens": 16885576,
      "responses": 52002,
      "gpu_avg_power": 741.1276694703631,
      "cpu_avg_power": 190.7044271735991,
      "dram_avg_power": 20.362319685013347,
      "total_avg_power": 1331.0464480874316,
      "gpu_energy": 718222.2790181116,
      "cpu_energy": 184810.49075032954,
      "dram_energy": 19732.999121078512,
      "total_energy": 1289908.949300869,
      "energy_per_token": 0.07639117251912927,
      "gpu_energy_per_second": 741.1276694703631,
      "cpu_energy_per_second": 190.7044271735991,
      "dram_energy_per_second": 20.362319685013347,
      "total_energy_per_second": 1331.0464480874316,
      "gpu_energy_per_token": 0.042534662662269365,
      "cpu_energy_per_token": 0.010944873349320719,
      "dram_energy_per_token": 0.001168630499846645,
      "total_energy_per_token": 0.07639117251912927,
      "gpu_energy_per_response": 374.855051679599,
      "cpu_energy_per_response": 96.45641479662294,
      "dram_energy_per_response": 10.299060084070204,
      "total_energy_per_response": 673.2301405536894,
      "gpu0_power_watts": 370.03944867919506,
      "gpu1_power_watts": 371.08822079116806,
      "psys_power_watts": 0,
      "package-1_power_watts": 99.26237359726505,
      "package-1-dram_power_watts": 10.805955505718794,
      "package-0_power_watts": 91.44205357633405,
      "package-0-dram_power_watts": 9.556364179294555,
      "dram_domains": [
        "package-1-dram",
        "package-0-dram"
      ],
      "cpu_domain_power": {
        "psys": 0,
        "package-1": 99.26237359726505,
        "package-1-dram": 10.805955505718794,
        "package-0": 91.44205357633405,
        "package-0-dram": 9.556364179294555
      },
      "model": "models--meta-llama--Llama-3.1-8B",
      "batch_size": 512,
      "engine": "vllm",
      "gpu_energy_per_second_formatted": "741.13J/s",
      "cpu_energy_per_second_formatted": "190.70J/s",
      "dram_energy_per_second_formatted": "20.36J/s",
      "total_energy_per_second_formatted": "1331.05J/s",
      "gpu_energy_per_token_mj": 42.53466266226936,
      "cpu_energy_per_token_mj": 10.94487334932072,
      "dram_energy_per_token_mj": 1.1686304998466448,
      "total_energy_per_token_mj": 76.39117251912927,
      "gpu_power_formatted": "741.13W",
      "cpu_power_formatted": "190.70W",
      "dram_power_formatted": "20.36W",
      "total_power_formatted": "1331.05W",
      "gpu_energy_formatted": "718222.28J",
      "cpu_energy_formatted": "184810.49J",
      "dram_energy_formatted": "19733.00J",
      "total_energy_formatted": "1289908.95J",
      "gpu_energy_per_response_formatted": "374.855J/response",
      "cpu_energy_per_response_formatted": "96.456J/response",
      "dram_energy_per_response_formatted": "10.299J/response",
      "total_energy_per_response_formatted": "673.230J/response",
      "formatted_output": "\nPower and Energy Metrics:\n==================================================\n\nBasic Information:\n  Runtime: 969.09s\n  Generated tokens: 16885576\n  Number of responses: 52002\n\nAverage Power:\n  GPU Power: 741.13W\n  CPU Power: 190.70W\n  DRAM Power: 20.36W\n  Total Power: 1331.05W\n\nTotal Energy Consumption:\n  GPU Energy: 718222.28J\n  CPU Energy: 184810.49J\n  DRAM Energy: 19733.00J\n  Total Energy: 1289908.95J\n\nEnergy per Second:\n  GPU Energy/s: 741.13J/s\n  CPU Energy/s: 190.70J/s\n  DRAM Energy/s: 20.36J/s\n  Total Energy/s: 1331.05J/s\n\nEnergy per Token:\n  GPU Energy/token: 42.535mJ/token\n  CPU Energy/token: 10.945mJ/token\n  DRAM Energy/token: 1.169mJ/token\n  Total Energy/token: 76.391mJ/token\n\nEnergy per Response:\n  GPU Energy/response: 374.855J/response\n  CPU Energy/response: 96.456J/response\n  DRAM Energy/response: 10.299J/response\n  Total Energy/response: 673.230J/response\n=================================================="
    }
  ]
}