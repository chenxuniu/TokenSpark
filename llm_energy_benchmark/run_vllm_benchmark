#!/bin/bash
#SBATCH --job-name=vllm-benchmark
#SBATCH --output=benchmark.out
#SBATCH --error=benchmark.err
#SBATCH --partition=h100
#SBATCH --gres=gpu:1
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=16
#SBATCH --mem=64G
#SBATCH --time=02:00:00

source ~/.bashrc
conda activate repacss-llm

cd /mnt/REPACSS/home/tongywan/llm_energy_benchmark

python llm_benchmark.py \
  --engine vllm \
  --models Llama-3.2-3B \
  --batch-sizes 32,64 \
  --output-tokens 200 \
  --num-samples 512 \
  --min-length 5 \
  --max-length 50
