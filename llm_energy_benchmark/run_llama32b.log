Loading Alpaca dataset...
Loaded 52002 prompts from Alpaca dataset
INFO 05-29 07:33:20 [__init__.py:243] Automatically detected platform cuda.
DeepSpeed not available. Please install it using: pip install deepspeed transformers
TensorRT-LLM not available. Please install it using: pip install tensorrt-llm
Loading Alpaca dataset...
Loaded 52002 raw prompts from Alpaca dataset
Filtered to 50992 prompts between 5 and 50 words

============================================================
Benchmarking model with vllm: Llama-3.2-3B
============================================================
Found 4 GPUs
GPU 0: NVIDIA H100 NVL
GPU 1: NVIDIA H100 NVL
GPU 2: NVIDIA H100 NVL
GPU 3: NVIDIA H100 NVL
Found 5 CPU RAPL domains:
  - psys
  - package-1
  - package-1-dram
  - package-0
  - package-0-dram
DRAM power monitoring is available!
Total system power monitoring not available
Using model path: /mnt/REPACSS/home/tongywan/models/Llama-3.2-3B
Loading model from /mnt/REPACSS/home/tongywan/models/Llama-3.2-3B with vLLM...
Setting tensor_parallel_size to 4 (available GPUs: 4)
Using max_model_len: 131072
INFO 05-29 07:33:25 [__init__.py:31] Available plugins for group vllm.general_plugins:
INFO 05-29 07:33:25 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
INFO 05-29 07:33:25 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 05-29 07:33:34 [config.py:793] This model supports multiple tasks: {'score', 'reward', 'generate', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-29 07:33:34 [config.py:1875] Defaulting to use mp for distributed inference
INFO 05-29 07:33:34 [config.py:2118] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 05-29 07:33:36 [core.py:438] Waiting for init message from front-end.
INFO 05-29 07:33:36 [core.py:65] Initializing a V1 LLM engine (v0.9.0) with config: model='/mnt/REPACSS/home/tongywan/models/Llama-3.2-3B', speculative_config=None, tokenizer='/mnt/REPACSS/home/tongywan/models/Llama-3.2-3B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/mnt/REPACSS/home/tongywan/models/Llama-3.2-3B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level": 3, "custom_ops": ["none"], "splitting_ops": ["vllm.unified_attention", "vllm.unified_attention_with_output"], "compile_sizes": [], "inductor_compile_config": {"enable_auto_functionalized_v2": false}, "use_cudagraph": true, "cudagraph_num_of_warmups": 1, "cudagraph_capture_sizes": [512, 504, 496, 488, 480, 472, 464, 456, 448, 440, 432, 424, 416, 408, 400, 392, 384, 376, 368, 360, 352, 344, 336, 328, 320, 312, 304, 296, 288, 280, 272, 264, 256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176, 168, 160, 152, 144, 136, 128, 120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 4, 2, 1], "max_capture_size": 512}
INFO 05-29 07:33:36 [shm_broadcast.py:250] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_cda92b39'), local_subscribe_addr='ipc:///tmp/4d6021ae-043e-4d6d-8f5d-315fc6d8f044', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 05-29 07:33:37 [utils.py:2671] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x149e32553070>
WARNING 05-29 07:33:37 [utils.py:2671] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x149e333d9e80>
[1;36m(VllmWorker rank=3 pid=12741)[0;0m INFO 05-29 07:33:37 [shm_broadcast.py:250] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_9f9ba5c1'), local_subscribe_addr='ipc:///tmp/e5c00c81-0419-426b-827c-6eaef8773e36', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 05-29 07:33:37 [utils.py:2671] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x149e333d9610>
[1;36m(VllmWorker rank=2 pid=12740)[0;0m INFO 05-29 07:33:37 [shm_broadcast.py:250] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_031ea5f4'), local_subscribe_addr='ipc:///tmp/f50562b9-a2ea-48ec-85cb-d5707f29ce62', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 05-29 07:33:37 [utils.py:2671] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x149e333d9820>
[1;36m(VllmWorker rank=1 pid=12739)[0;0m INFO 05-29 07:33:37 [shm_broadcast.py:250] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_33222ba0'), local_subscribe_addr='ipc:///tmp/fc5ae1ea-8311-43f7-a8b1-d13ff263e149', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=12738)[0;0m INFO 05-29 07:33:37 [shm_broadcast.py:250] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_91037bc1'), local_subscribe_addr='ipc:///tmp/09daf1e2-9726-43b7-9fa2-8a397616798c', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=12741)[0;0m INFO 05-29 07:33:42 [utils.py:1077] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=12741)[0;0m INFO 05-29 07:33:42 [pynccl.py:69] vLLM is using nccl==2.26.2
[1;36m(VllmWorker rank=1 pid=12739)[0;0m INFO 05-29 07:33:42 [utils.py:1077] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=12739)[0;0m INFO 05-29 07:33:42 [pynccl.py:69] vLLM is using nccl==2.26.2
[1;36m(VllmWorker rank=0 pid=12738)[0;0m INFO 05-29 07:33:42 [utils.py:1077] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=12738)[0;0m INFO 05-29 07:33:42 [pynccl.py:69] vLLM is using nccl==2.26.2
[1;36m(VllmWorker rank=2 pid=12740)[0;0m INFO 05-29 07:33:42 [utils.py:1077] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=12740)[0;0m INFO 05-29 07:33:42 [pynccl.py:69] vLLM is using nccl==2.26.2
[1;36m(VllmWorker rank=3 pid=12741)[0;0m WARNING 05-29 07:33:49 [custom_all_reduce.py:136] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker rank=2 pid=12740)[0;0m WARNING 05-29 07:33:49 [custom_all_reduce.py:136] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker rank=0 pid=12738)[0;0m WARNING 05-29 07:33:49 [custom_all_reduce.py:136] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker rank=1 pid=12739)[0;0m WARNING 05-29 07:33:49 [custom_all_reduce.py:136] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker rank=0 pid=12738)[0;0m INFO 05-29 07:33:49 [shm_broadcast.py:250] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_43cc1fbf'), local_subscribe_addr='ipc:///tmp/1b1b40f8-d580-4669-84db-a86b927d99c6', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=12738)[0;0m INFO 05-29 07:33:49 [parallel_state.py:1064] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(VllmWorker rank=1 pid=12739)[0;0m INFO 05-29 07:33:49 [parallel_state.py:1064] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1
[1;36m(VllmWorker rank=3 pid=12741)[0;0m INFO 05-29 07:33:49 [parallel_state.py:1064] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3, EP rank 3
[1;36m(VllmWorker rank=2 pid=12740)[0;0m INFO 05-29 07:33:49 [parallel_state.py:1064] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2, EP rank 2
[1;36m(VllmWorker rank=2 pid=12740)[0;0m WARNING 05-29 07:33:49 [topk_topp_sampler.py:58] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=3 pid=12741)[0;0m WARNING 05-29 07:33:49 [topk_topp_sampler.py:58] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=1 pid=12739)[0;0m WARNING 05-29 07:33:49 [topk_topp_sampler.py:58] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=0 pid=12738)[0;0m WARNING 05-29 07:33:49 [topk_topp_sampler.py:58] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=3 pid=12741)[0;0m INFO 05-29 07:33:50 [gpu_model_runner.py:1531] Starting to load model /mnt/REPACSS/home/tongywan/models/Llama-3.2-3B...
[1;36m(VllmWorker rank=1 pid=12739)[0;0m INFO 05-29 07:33:50 [gpu_model_runner.py:1531] Starting to load model /mnt/REPACSS/home/tongywan/models/Llama-3.2-3B...
[1;36m(VllmWorker rank=2 pid=12740)[0;0m INFO 05-29 07:33:50 [gpu_model_runner.py:1531] Starting to load model /mnt/REPACSS/home/tongywan/models/Llama-3.2-3B...
[1;36m(VllmWorker rank=0 pid=12738)[0;0m INFO 05-29 07:33:50 [gpu_model_runner.py:1531] Starting to load model /mnt/REPACSS/home/tongywan/models/Llama-3.2-3B...
[1;36m(VllmWorker rank=1 pid=12739)[0;0m INFO 05-29 07:33:50 [cuda.py:217] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=12741)[0;0m INFO 05-29 07:33:50 [cuda.py:217] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=12738)[0;0m INFO 05-29 07:33:50 [cuda.py:217] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=12740)[0;0m INFO 05-29 07:33:50 [cuda.py:217] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=12741)[0;0m INFO 05-29 07:33:50 [backends.py:35] Using InductorAdaptor
[1;36m(VllmWorker rank=1 pid=12739)[0;0m INFO 05-29 07:33:50 [backends.py:35] Using InductorAdaptor
[1;36m(VllmWorker rank=2 pid=12740)[0;0m INFO 05-29 07:33:50 [backends.py:35] Using InductorAdaptor
[1;36m(VllmWorker rank=0 pid=12738)[0;0m INFO 05-29 07:33:50 [backends.py:35] Using InductorAdaptor
[1;36m(VllmWorker rank=0 pid=12738)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(VllmWorker rank=0 pid=12738)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:04<00:04,  4.60s/it]
[1;36m(VllmWorker rank=0 pid=12738)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:05<00:00,  2.34s/it]
[1;36m(VllmWorker rank=0 pid=12738)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:05<00:00,  2.68s/it]
[1;36m(VllmWorker rank=0 pid=12738)[0;0m 
[1;36m(VllmWorker rank=3 pid=12741)[0;0m INFO 05-29 07:33:56 [default_loader.py:280] Loading weights took 5.42 seconds
[1;36m(VllmWorker rank=1 pid=12739)[0;0m INFO 05-29 07:33:56 [default_loader.py:280] Loading weights took 5.42 seconds
[1;36m(VllmWorker rank=0 pid=12738)[0;0m INFO 05-29 07:33:56 [default_loader.py:280] Loading weights took 5.40 seconds
[1;36m(VllmWorker rank=2 pid=12740)[0;0m INFO 05-29 07:33:56 [default_loader.py:280] Loading weights took 5.42 seconds
[1;36m(VllmWorker rank=1 pid=12739)[0;0m INFO 05-29 07:33:58 [gpu_model_runner.py:1549] Model loading took 1.5346 GiB and 6.263057 seconds
[1;36m(VllmWorker rank=3 pid=12741)[0;0m INFO 05-29 07:33:58 [gpu_model_runner.py:1549] Model loading took 1.5346 GiB and 6.258913 seconds
[1;36m(VllmWorker rank=2 pid=12740)[0;0m INFO 05-29 07:33:59 [gpu_model_runner.py:1549] Model loading took 1.5346 GiB and 6.326841 seconds
[1;36m(VllmWorker rank=0 pid=12738)[0;0m INFO 05-29 07:33:59 [gpu_model_runner.py:1549] Model loading took 1.5346 GiB and 6.309955 seconds
ERROR 05-29 07:34:04 [multiproc_executor.py:135] Worker proc VllmWorker-1 died unexpectedly, shutting down executor.
Traceback (most recent call last):
  File "/mnt/REPACSS/home/tongywan/llm_energy_benchmark/llm_benchmark.py", line 215, in <module>
    main()
  File "/mnt/REPACSS/home/tongywan/llm_energy_benchmark/llm_benchmark.py", line 203, in main
    results = run_benchmark(args.engine, models, batch_sizes, args.num_samples, args.output_tokens, prompts)
  File "/mnt/REPACSS/home/tongywan/llm_energy_benchmark/llm_benchmark.py", line 102, in run_benchmark
    model_instance = engine.setup_model(model_path)
  File "/mnt/REPACSS/home/tongywan/llm_energy_benchmark/engines/vllm_engine.py", line 68, in setup_model
    llm = LLM(
  File "/mnt/REPACSS/home/tongywan/miniforge3/envs/repacss-llm/lib/python3.9/site-packages/vllm/utils.py", line 1183, in inner
    return fn(*args, **kwargs)
  File "/mnt/REPACSS/home/tongywan/miniforge3/envs/repacss-llm/lib/python3.9/site-packages/vllm/entrypoints/llm.py", line 253, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
  File "/mnt/REPACSS/home/tongywan/miniforge3/envs/repacss-llm/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 501, in from_engine_args
    return engine_cls.from_vllm_config(
  File "/mnt/REPACSS/home/tongywan/miniforge3/envs/repacss-llm/lib/python3.9/site-packages/vllm/v1/engine/llm_engine.py", line 123, in from_vllm_config
    return cls(vllm_config=vllm_config,
  File "/mnt/REPACSS/home/tongywan/miniforge3/envs/repacss-llm/lib/python3.9/site-packages/vllm/v1/engine/llm_engine.py", line 100, in __init__
    self.engine_core = EngineCoreClient.make_client(
  File "/mnt/REPACSS/home/tongywan/miniforge3/envs/repacss-llm/lib/python3.9/site-packages/vllm/v1/engine/core_client.py", line 75, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
  File "/mnt/REPACSS/home/tongywan/miniforge3/envs/repacss-llm/lib/python3.9/site-packages/vllm/v1/engine/core_client.py", line 580, in __init__
    super().__init__(
  File "/mnt/REPACSS/home/tongywan/miniforge3/envs/repacss-llm/lib/python3.9/site-packages/vllm/v1/engine/core_client.py", line 418, in __init__
    self._wait_for_engine_startup(output_address, parallel_config)
  File "/mnt/REPACSS/home/tongywan/miniforge3/envs/repacss-llm/lib/python3.9/site-packages/vllm/v1/engine/core_client.py", line 469, in _wait_for_engine_startup
    events = poller.poll(STARTUP_POLL_PERIOD_MS)
  File "/mnt/REPACSS/home/tongywan/miniforge3/envs/repacss-llm/lib/python3.9/site-packages/zmq/sugar/poll.py", line 106, in poll
    return zmq_poll(self.sockets, timeout=timeout)
  File "_zmq.py", line 1609, in zmq.backend.cython._zmq.zmq_poll
  File "_zmq.py", line 169, in zmq.backend.cython._zmq._check_rc
KeyboardInterrupt
/mnt/REPACSS/home/tongywan/miniforge3/envs/repacss-llm/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
