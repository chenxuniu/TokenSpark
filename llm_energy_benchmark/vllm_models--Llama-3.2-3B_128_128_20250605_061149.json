{
  "Llama-3.2-3B": [
    {
      "duration": 3.782503128051758,
      "total_output_tokens": 51140,
      "responses": 512,
      "gpu_avg_power": 405.7666875,
      "cpu_avg_power": 0.0,
      "dram_avg_power": 0.0,
      "total_avg_power": 0,
      "gpu_energy": 1534.81376472795,
      "cpu_energy": 0.0,
      "dram_energy": 0.0,
      "total_energy": 1534.81376472795,
      "energy_per_token": 0.030012001656784318,
      "gpu_energy_per_second": 405.7666875,
      "cpu_energy_per_second": 0.0,
      "dram_energy_per_second": 0.0,
      "total_energy_per_second": 0.0,
      "gpu_energy_per_token": 0.030012001656784318,
      "cpu_energy_per_token": 0.0,
      "dram_energy_per_token": 0.0,
      "total_energy_per_token": 0.0,
      "gpu_energy_per_response": 102.32091764853,
      "cpu_energy_per_response": 0.0,
      "dram_energy_per_response": 0.0,
      "total_energy_per_response": 0.0,
      "gpu0_power_watts": 219.476390625,
      "gpu1_power_watts": 63.75939062499999,
      "gpu2_power_watts": 62.114656249999996,
      "gpu3_power_watts": 60.416249999999984,
      "psys_power_watts": 0.0,
      "package-1_power_watts": 0.0,
      "package-1-dram_power_watts": 0.0,
      "package-0_power_watts": 0.0,
      "package-0-dram_power_watts": 0.0,
      "dram_domains": [
        "package-1-dram",
        "package-0-dram"
      ],
      "cpu_domain_power": {
        "psys": 0.0,
        "package-1": 0.0,
        "package-1-dram": 0.0,
        "package-0": 0.0,
        "package-0-dram": 0.0
      },
      "gpu_memory_after_load_mb": 87008.56,
      "gpu_memory_total_mb": 95830.0,
      "model": "Llama-3.2-3B",
      "batch_size": 128,
      "engine": "vllm",
      "gpu_energy_per_second_formatted": "405.77J/s",
      "cpu_energy_per_second_formatted": "0.00J/s",
      "dram_energy_per_second_formatted": "0.00J/s",
      "total_energy_per_second_formatted": "0.00J/s",
      "gpu_energy_per_token_mj": 30.012001656784317,
      "cpu_energy_per_token_mj": 0.0,
      "dram_energy_per_token_mj": 0.0,
      "total_energy_per_token_mj": 0.0,
      "gpu_power_formatted": "405.77W",
      "cpu_power_formatted": "0.00W",
      "dram_power_formatted": "0.00W",
      "total_power_formatted": "0.00W",
      "gpu_energy_formatted": "1534.81J",
      "cpu_energy_formatted": "0.00J",
      "dram_energy_formatted": "0.00J",
      "total_energy_formatted": "1534.81J",
      "gpu_energy_per_response_formatted": "102.321J/response",
      "cpu_energy_per_response_formatted": "0.000J/response",
      "dram_energy_per_response_formatted": "0.000J/response",
      "total_energy_per_response_formatted": "0.000J/response",
      "formatted_output": "\nPower and Energy Metrics:\n==================================================\n\nBasic Information:\n  Runtime: 3.78s\n  Generated tokens: 51140\n  Number of responses: 512\n\nAverage Power:\n  GPU Power: 405.77W\n  CPU Power: 0.00W\n  DRAM Power: 0.00W\n  Total Power: 0.00W\n\nTotal Energy Consumption:\n  GPU Energy: 1534.81J\n  CPU Energy: 0.00J\n  DRAM Energy: 0.00J\n  Total Energy: 1534.81J\n\nEnergy per Second:\n  GPU Energy/s: 405.77J/s\n  CPU Energy/s: 0.00J/s\n  DRAM Energy/s: 0.00J/s\n  Total Energy/s: 0.00J/s\n\nEnergy per Token:\n  GPU Energy/token: 30.012mJ/token\n  CPU Energy/token: 0.000mJ/token\n  DRAM Energy/token: 0.000mJ/token\n  Total Energy/token: 0.000mJ/token\n\nEnergy per Response:\n  GPU Energy/response: 102.321J/response\n  CPU Energy/response: 0.000J/response\n  DRAM Energy/response: 0.000J/response\n  Total Energy/response: 0.000J/response\n=================================================="
    }
  ]
}