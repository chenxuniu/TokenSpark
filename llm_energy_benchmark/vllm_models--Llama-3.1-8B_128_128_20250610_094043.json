{
  "Llama-3.1-8B": [
    {
      "duration": 1.0050084590911865,
      "total_output_tokens": 3833,
      "responses": 32,
      "gpu_avg_power": 344.83237499999996,
      "cpu_avg_power": 0.0,
      "dram_avg_power": 0.0,
      "total_avg_power": 0,
      "gpu_energy": 346.5594538435042,
      "cpu_energy": 0.0,
      "dram_energy": 0.0,
      "total_energy": 346.5594538435042,
      "energy_per_token": 0.09041467619188734,
      "gpu_energy_per_second": 344.83237499999996,
      "cpu_energy_per_second": 0.0,
      "dram_energy_per_second": 0.0,
      "total_energy_per_second": 0.0,
      "gpu_energy_per_token": 0.09041467619188734,
      "cpu_energy_per_token": 0.0,
      "dram_energy_per_token": 0.0,
      "total_energy_per_token": 0.0,
      "gpu_energy_per_response": 38.506605982611575,
      "cpu_energy_per_response": 0.0,
      "dram_energy_per_response": 0.0,
      "total_energy_per_response": 0.0,
      "gpu0_power_watts": 159.8575,
      "gpu1_power_watts": 60.50692500000001,
      "gpu2_power_watts": 63.307075,
      "gpu3_power_watts": 61.16087499999999,
      "psys_power_watts": 0.0,
      "package-1_power_watts": 0.0,
      "package-1-dram_power_watts": 0.0,
      "package-0_power_watts": 0.0,
      "package-0-dram_power_watts": 0.0,
      "dram_domains": [
        "package-1-dram",
        "package-0-dram"
      ],
      "cpu_domain_power": {
        "psys": 0.0,
        "package-1": 0.0,
        "package-1-dram": 0.0,
        "package-0": 0.0,
        "package-0-dram": 0.0
      },
      "gpu_memory_after_load_mb": 87172.56,
      "gpu_memory_total_mb": 95830.0,
      "model": "Llama-3.1-8B",
      "batch_size": 128,
      "engine": "vllm",
      "gpu_energy_per_second_formatted": "344.83J/s",
      "cpu_energy_per_second_formatted": "0.00J/s",
      "dram_energy_per_second_formatted": "0.00J/s",
      "total_energy_per_second_formatted": "0.00J/s",
      "gpu_energy_per_token_mj": 90.41467619188734,
      "cpu_energy_per_token_mj": 0.0,
      "dram_energy_per_token_mj": 0.0,
      "total_energy_per_token_mj": 0.0,
      "gpu_power_formatted": "344.83W",
      "cpu_power_formatted": "0.00W",
      "dram_power_formatted": "0.00W",
      "total_power_formatted": "0.00W",
      "gpu_energy_formatted": "346.56J",
      "cpu_energy_formatted": "0.00J",
      "dram_energy_formatted": "0.00J",
      "total_energy_formatted": "346.56J",
      "gpu_energy_per_response_formatted": "38.507J/response",
      "cpu_energy_per_response_formatted": "0.000J/response",
      "dram_energy_per_response_formatted": "0.000J/response",
      "total_energy_per_response_formatted": "0.000J/response",
      "formatted_output": "\nPower and Energy Metrics:\n==================================================\n\nBasic Information:\n  Runtime: 1.01s\n  Generated tokens: 3833\n  Number of responses: 32\n\nAverage Power:\n  GPU Power: 344.83W\n  CPU Power: 0.00W\n  DRAM Power: 0.00W\n  Total Power: 0.00W\n\nTotal Energy Consumption:\n  GPU Energy: 346.56J\n  CPU Energy: 0.00J\n  DRAM Energy: 0.00J\n  Total Energy: 346.56J\n\nEnergy per Second:\n  GPU Energy/s: 344.83J/s\n  CPU Energy/s: 0.00J/s\n  DRAM Energy/s: 0.00J/s\n  Total Energy/s: 0.00J/s\n\nEnergy per Token:\n  GPU Energy/token: 90.415mJ/token\n  CPU Energy/token: 0.000mJ/token\n  DRAM Energy/token: 0.000mJ/token\n  Total Energy/token: 0.000mJ/token\n\nEnergy per Response:\n  GPU Energy/response: 38.507J/response\n  CPU Energy/response: 0.000J/response\n  DRAM Energy/response: 0.000J/response\n  Total Energy/response: 0.000J/response\n=================================================="
    }
  ]
}